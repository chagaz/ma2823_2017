{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#  2017-11-10  Regularization\n",
    "\n",
    "The goal of this lab is to explore and understand l1 and l2 regularization of linear models.\n",
    "\n",
    "The lab starts with a classification example using scikit-learn, which should be your focus. You can then use it to explore regression examples (Bonus 1), understand how to implement these algorithms (Bonus 2), combine feature selection (PCA) and logistic/linear regression with scikit-learn pipelines (Bonus 3). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1. Classification data\n",
    "\n",
    "We will use the same data as in Lab 4: the samples are tumors, each described by the expression (= the abundance) of 3,000 genes. The goal is to separate the endometrium tumors from the uterine ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the endometrium vs. uterus tumor data\n",
    "endometrium_data = pd.read_csv('data/small_Endometrium_Uterus.csv', sep=\",\")  # load data\n",
    "endometrium_data.head(n=5)  # adjust n to view more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create the design matrix and target vector\n",
    "X_clf = endometrium_data.drop(['ID_REF', 'Tissue'], axis=1).values\n",
    "y_clf = pd.get_dummies(endometrium_data['Tissue']).values[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ Split the data in a train set containing 70% of the data and a test set containing the remaining 30%. We use [model_selection.train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "Xtr, Xte, ytr, yte = model_selection.train_test_split(X_clf, y_clf, \n",
    "                                                      test_size=#TODO, \n",
    "                                                      random_state=27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let us also compute a scaled version of the data. The data is scaled on the _train_ set, and the scaling parameters (mean, standard deviation) are applied to the test set. __Question:__ Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "Xtr_scaled = scaler.fit_transform(Xtr)\n",
    "Xte_scaled = scaler.transform(Xte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2. Logistic regression, not regularized \n",
    "\n",
    "Let us train a logisitic regression _without regularization_ on our train set, and evaluate it on the test set. This is similar to Lab 4 and will serve as a comparison point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Logistic regression (no regularization, no scaling)\n",
    "from sklearn import linear_model\n",
    "clf_logreg = linear_model.LogisticRegression(C=1e6) # large C = no regularization\n",
    "\n",
    "# Train the model\n",
    "clf_logreg.fit(Xtr, ytr)\n",
    "\n",
    "# Predict on the test set\n",
    "# Predicted probabilities of belonging to the positive class\n",
    "pos_idx = list(clf_logreg.classes_).index(1)\n",
    "ypred_logreg = clf_logreg.predict_proba(Xte)[:, pos_idx]\n",
    "\n",
    "# Predicted binary labels\n",
    "ypred_logreg_b = np.where(ypred_logreg > 0.5, 1, 0)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"No regularization: accuracy = %.3f\" % metrics.accuracy_score(yte, ypred_logreg_b))\n",
    "print(\"AUC = %.3f\" % (metrics.roc_auc_score(yte, ypred_logreg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ Repeat the experiment on the scaled data. What do you observe in terms of performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Logistic regression (no regularization, scaling)\n",
    "clf_logreg_s = linear_model.LogisticRegression(C=1e6)\n",
    "\n",
    "# Train the model\n",
    "# TODO\n",
    "\n",
    "# Predict on the test set\n",
    "# Predicted probabilities of belonging to the positive class\n",
    "pos_idx = list(clf_logreg_s.classes_).index(1)\n",
    "ypred_logreg_s = # TODO\n",
    "# Predicted binary labels\n",
    "ypred_logreg_s_b = # TODO\n",
    "\n",
    "print(\"Scaled, no regularization: accuracy = %.3f\" % metrics.accuracy_score(yte, ypred_logreg_s_b))\n",
    "print(\"AUC = %.3f\" % (metrics.roc_auc_score(yte, ypred_logreg_s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3. L2-regularized logistic regression \n",
    "\n",
    "__Question:__ What is the role of L2 regularization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let us use an l2-regularized logistic regression with the parameter `C` set to 0.01. \n",
    "\n",
    "__Question:__ What is the role of `C`? How does it relate to the `lambda` regularization parameter we have seen in class?\n",
    "\n",
    "__Question:__ Train the l2-regularized logistic regression initialized below on the scaled training data, and evaluate it on the sclaed test set (as above). How does the performance evolve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cvalue = 0.01\n",
    "clf_logreg_l2_s = linear_model.LogisticRegression(C=cvalue, penalty='l2')\n",
    "\n",
    "# Train the model\n",
    "# TODO\n",
    "\n",
    "# index of positive class\n",
    "pos_idx = list(clf_logreg_l2_s.classes_).index(1)\n",
    "# predict probability of being positive\n",
    "ypred_logreg_l2_s = # TODO\n",
    "# predict binary labels\n",
    "ypred_logreg_l2_s_b = np.where(ypred_logreg_l2_s > 0.5, 1, 0)\n",
    "\n",
    "print(\"Scaled, l2 regularization (C=%.2e): accuracy = %.3f\" % (cvalue, \n",
    "                                                               metrics.accuracy_score(yte, ypred_logreg_l2_s_b)))\n",
    "print(\"AUC = %.3f\" % (metrics.roc_auc_score(yte, ypred_logreg_l2_s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.1 Effect of L2-regularization on the logistic regression coefficients\n",
    "\n",
    "We will now look at how the regression coefficients have evolved between the non-regularized and the regularized versions of the logistic regression.\n",
    "\n",
    "__Question:__ Fill in the blanks below to plot the regression coefficients of both the trained `clf_logreg_l2_s` and `clf_logreg_s` models. Use the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) to figure out how to access these coefficients. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Effect of l2-regularization on the weights\n",
    "num_features = X_clf.shape[1]\n",
    "plt.scatter(range(num_features), # TODO, \n",
    "            color='blue', marker='x', label='Logistic regression')\n",
    "plt.scatter(range(num_features), #TODO, \n",
    "            color='orange', marker='+', label='L2-regularized logistic regression')\n",
    "\n",
    "plt.xlabel('Genes', fontsize=16)\n",
    "plt.ylabel('Weights', fontsize=16)\n",
    "plt.title('Logistic regression weights', fontsize=16)\n",
    "plt.legend(fontsize=14, loc=(1.05, 0))\n",
    "plt.xlim([0, num_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3.2 Optimization of the regularization parameter\n",
    "\n",
    "We will now use a 3-fold cross-validation on the training set to optimize the value of C. Scikit-learn makes it really easy to use a cross-validation to choose a good value for $\\alpha$ among a grid of several choices. Check the [GridSearchCV class](http://scikit-learn.org/0.17/modules/generated/sklearn.grid_search.GridSearchCV.html#sklearn.grid_search.GridSearchCV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create a range of values to test for the parameter C\n",
    "cvalues_list = np.logspace(-5, 1, 20)\n",
    "print(cvalues_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ Fill in the blanks below to find the optimal value of the parameter C.\n",
    "\n",
    "Use the `.best_estimator_` attribute of a `GridSearchCV`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Optimize cvalue\n",
    "classifier = linear_model.LogisticRegression(penalty='l2')\n",
    "param_grid = {'C': #TODO\n",
    "             }\n",
    "clf_logreg_l2_s_opt = model_selection.GridSearchCV(#TODO, \n",
    "                                                   #TODO, \n",
    "                                                   cv=3)     \n",
    "\n",
    "# Train the model\n",
    "# TODO\n",
    "\n",
    "# index of the positive class\n",
    "pos_idx = # TODO\n",
    "# predict probability of being positive\n",
    "ypred_logreg_l2_s_opt = # TODO\n",
    "# predict binary label\n",
    "ypred_logreg_l2_s_opt_b = # TODO\n",
    "\n",
    "# optimal value of C\n",
    "cvalue_opt = # TODO\n",
    "print(\"Scaled, l2 regularization (C=%.2e): accuracy = %.3f\" % (cvalue_opt, \n",
    "                                                               metrics.accuracy_score(yte, ypred_logreg_l2_s_opt_b)))\n",
    "print(\"AUC = %.3f\" % (metrics.roc_auc_score(yte, ypred_logreg_l2_s_opt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ Fill in the code below to compare the ROC curves of the non-regularized and l2-regularized logistic regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fpr_logreg_s, tpr_logreg_s, t = # TODO\n",
    "auc_logreg_s = metrics.auc(fpr_logreg_s, tpr_logreg_s)\n",
    "plt.plot(fpr_logreg_s, tpr_logreg_s, color='blue', \n",
    "         label='No regularization: AUC = %0.3f' % auc_logreg_s)\n",
    "\n",
    "fpr_logreg_l2_s_opt, tpr_logreg_l2_s_opt, t = # TODO\n",
    "auc_logreg_l2_s_opt = metrics.auc(fpr_logreg_l2_s_opt, tpr_logreg_l2_s_opt)\n",
    "plt.plot(fpr_logreg_l2_s_opt, tpr_logreg_l2_s_opt, color='orange', \n",
    "         label='L2 regularization: AUC = %0.3f' % auc_logreg_l2_s_opt)\n",
    "\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "plt.title('ROC curve: Logistic regression', fontsize=16)\n",
    "plt.legend(fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ Is the optimal C larger or smaller than the one we tried before? Does this mean more or less regularization? Do you expect larger or smaller regularization coefficients?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ Fill in the blanks to compare the regularization weights of the different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Effect of l2-regularization on the weights\n",
    "num_features = X_clf.shape[1]\n",
    "plt.scatter(range(num_features), # TODO, \n",
    "            color='blue', marker='x', label='Logistic regression')\n",
    "plt.scatter(range(num_features), # TODO, \n",
    "            color='orange', marker='+', label='L2-regularized logistic regression')\n",
    "plt.scatter(range(num_features), # TODO, \n",
    "            color='magenta', marker='.', label='L2-regularized logistic regression (opt)')\n",
    "\n",
    "plt.xlabel('Genes', fontsize=16)\n",
    "plt.ylabel('Weights', fontsize=16)\n",
    "plt.title('Logistic regression weights', fontsize=16)\n",
    "plt.legend(fontsize=14, loc=(1.05, 0))\n",
    "plt.xlim([0, num_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 4. L1-regularized logistic regression\n",
    "\n",
    "__Question:__ What is the role of the l1-regularized logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ Instead of a l2-regularized logistic regression with `C=0.01`, now train and evaluate a __l1__-regularized logistic regression with __`C=10.0`__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cvalue = # TODO\n",
    "clf_logreg_l1_s = # TODO\n",
    "clf_logreg_l1_s.fit(Xtr_scaled, ytr)\n",
    "\n",
    "# index of the positive class\n",
    "pos_idx = list(clf_logreg_l1_s.classes_).index(1)\n",
    "# predict the probability of belonging to the positive class\n",
    "ypred_logreg_l1_s = clf_logreg_l1_s.predict_proba(Xte_scaled)[:, pos_idx]\n",
    "# predict binary labels\n",
    "ypred_logreg_l1_s_b = np.where(ypred_logreg_l1_s > 0.5, 1, 0)\n",
    "\n",
    "print(\"Scaled, l1 regularization (C=%.2e): accuracy = %.3f\" % (cvalue, \n",
    "                                                               metrics.accuracy_score(yte, ypred_logreg_l1_s_b)))\n",
    "print(\"AUC = %.3f\" % (metrics.roc_auc_score(yte, ypred_logreg_l1_s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question__: How did the performance evolve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.1 Effect of regularization on the regression coefficients\n",
    "\n",
    "__Question:__ Plot the weights that were given to each feature in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_features = X_clf.shape[1]\n",
    "plt.scatter(range(num_features), #TODO, \n",
    "            color='blue', marker='x', label='Logistic regression')\n",
    "plt.scatter(range(num_features), #TODO, \n",
    "            color='orange', marker='+', label='L1-regularized logistic regression')\n",
    "\n",
    "plt.xlabel('Genes', fontsize=16)\n",
    "plt.ylabel('Weights', fontsize=16)\n",
    "plt.title('Logistic regression weights', fontsize=16)\n",
    "plt.legend(fontsize=14, loc=(1.05, 0))\n",
    "plt.xlim([0, num_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ What do you observe? How does this differ from l2-regularization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ How many weights are different from zero? How many features are _not_ used by the l1-regularized model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Number of selected features\n",
    "print(\"The non-regularized logistic regression uses %d features\" % len(np.where(clf_logreg_s.coef_ !=0)[1]))\n",
    "print(\"The L2-regularized logistic regression uses %d features\" % #TODO\n",
    "     )\n",
    "print(\"The L1-regularized logistic regression uses %d features\" % #TODO\n",
    "     )\n",
    "\n",
    "print(\"Number of features discarded by the L1-regularization: %d\" % #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.2 Optimization of the regularization parameter\n",
    "\n",
    "__Question:__ Fill in the blanks to optimize the value of `C` for l1-regularized logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Optimize cvalue\n",
    "cvalues_list = np.logspace(-2, 3, 20)\n",
    "print(cvalues_list)\n",
    "\n",
    "classifier = # TODO\n",
    "param_grid = # TODO\n",
    "clf_logreg_l1_s_opt = # TODO   \n",
    "\n",
    "# Train the model\n",
    "# TODO\n",
    "\n",
    "# index of the positive class\n",
    "pos_idx = # TODO\n",
    "# predict the probability of belonging to the positive class\n",
    "ypred_logreg_l1_s_opt = # TODO\n",
    "# predict binary labels\n",
    "ypred_logreg_l1_s_b = # TODO\n",
    "\n",
    "# optimal value of C\n",
    "cvalue_opt = # TODO\n",
    "\n",
    "print(\"Scaled, l1 regularization (C=%.2e): accuracy = %.3f\" % (cvalue_opt, \n",
    "                                                               metrics.accuracy_score(yte, ypred_logreg_l1_s_b)))\n",
    "print(\"AUC = %.3f\" % (metrics.roc_auc_score(yte, ypred_logreg_l1_s_opt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "fpr_logreg_s, tpr_logreg_s, t = # TODO\n",
    "auc_logreg_s = metrics.auc(fpr_logreg_s, tpr_logreg_s)\n",
    "plt.plot(fpr_logreg_s, tpr_logreg_s, color='blue', \n",
    "         label='No regularization: AUC = %0.3f' % auc_logreg_s)\n",
    "\n",
    "fpr_logreg_l2_s_opt, tpr_logreg_l2_s_opt, t = # TODO\n",
    "auc_logreg_l2_s_opt = metrics.auc(fpr_logreg_l2_s_opt, tpr_logreg_l2_s_opt)\n",
    "plt.plot(fpr_logreg_l2_s_opt, tpr_logreg_l2_s_opt, color='orange', \n",
    "         label='L2 regularization: AUC = %0.3f' % auc_logreg_l2_s_opt)\n",
    "\n",
    "fpr_logreg_l1_s_opt, tpr_logreg_l1_s_opt, t = metrics.roc_curve(yte, ypred_logreg_l1_s_opt, pos_label=1)\n",
    "auc_logreg_l1_s_opt = metrics.auc(fpr_logreg_l1_s_opt, tpr_logreg_l1_s_opt)\n",
    "plt.plot(fpr_logreg_l1_s_opt, tpr_logreg_l1_s_opt, color='magenta', \n",
    "         label='L1 regularization: AUC = %0.3f' % auc_logreg_l1_s_opt)\n",
    "\n",
    "plt.xlabel('False Positive Rate', fontsize=16)\n",
    "plt.ylabel('True Positive Rate', fontsize=16)\n",
    "plt.title('ROC curve: Logistic regression', fontsize=16)\n",
    "plt.legend(fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ How many genes does the l1-regularized approach select? How does this affect the performance, compared to `C=10.0` or the l2-regularized approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"The L1-regularized logistic regression uses %d features\" % # TODO\n",
    "     )\n",
    "print(\"The optimized L1-regularized logistic regression uses %d features\" % \\\n",
    "      # TODO\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ Compare the features selected with `C=0.01` and your optimal `C` value. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_features = X_clf.shape[1]\n",
    "plt.scatter(range(num_features), #TODO, \n",
    "            color='orange', marker='+', label='L1-regularized logistic regression')\n",
    "plt.scatter(range(num_features), #TODO, \n",
    "            color='magenta', marker='x', label='L1-regularized logistic regression (optimal C)')\n",
    "\n",
    "plt.xlabel('Genes', fontsize=16)\n",
    "plt.ylabel('Weights', fontsize=16)\n",
    "plt.title('Logistic regression weights', fontsize=16)\n",
    "plt.legend(fontsize=14, loc=(1.05, 0))\n",
    "plt.xlim([0, num_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Bonus 1. Regularized regression\n",
    "\n",
    "Here we guide you in using l1-regularized and l2-regularized linear regressions, aka lasso and ridge regression, respectively, on the same wine quality data as in Lab 4. We also use the same cross-validation set-up as in Lab 4; you might want to try a train/test setup similar to the one we set up here for the gene expression data.\n",
    "\n",
    "Regularization does not necessarily have much impact on this data set; you can also try this lab with the prostate data (used in the _Elements of Statistical Learning_ textbook), which you can download from https://rafalab.github.io/pages/649/prostate.html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load the data for regression\n",
    "wine_data = pd.read_csv('data/winequality-white.csv', sep=\";\")\n",
    "wine_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_regr = wine_data.drop(['quality'], axis=1).values\n",
    "y_regr = wine_data['quality'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Build cross-validation folds\n",
    "from sklearn import model_selection\n",
    "kf = model_selection.KFold(n_splits=5)\n",
    "kf.get_n_splits(X_regr)\n",
    "folds_regr = [(tr, te) for (tr, te) in kf.split(X_regr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Cross-validation procedure\n",
    "def cross_validate_regr(design_matrix, labels, regressor, cv_folds):\n",
    "    \"\"\" Perform a cross-validation and returns the predictions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    design_matrix: (n_samples, n_features) np.array\n",
    "        Design matrix for the experiment.\n",
    "    labels: (n_samples, ) np.array\n",
    "        Vector of labels.\n",
    "    regressor:  Regressor instance; must have the following methods:\n",
    "        - fit(X, y) to train the regressor on the data X, y\n",
    "        - predict(X) to apply the trained regressor to the data X and return estimates \n",
    "    cv_folds: sklearn cross-validation object\n",
    "        Cross-validation iterator.\n",
    "        \n",
    "    Return:\n",
    "    -------\n",
    "    pred: (n_samples, ) np.array\n",
    "        Vectors of predictions (same order as labels).\n",
    "    \"\"\"\n",
    "    pred = np.zeros(labels.shape)\n",
    "    for tr, te in cv_folds:\n",
    "        regressor.fit(design_matrix[tr,:], labels[tr])\n",
    "        pred[te] = (regressor.predict(design_matrix[te,:]))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Cross-validation procedure, with standardization\n",
    "from sklearn import preprocessing\n",
    "def cross_validate_regr_with_scaling(design_matrix, labels, regressor, cv_folds):\n",
    "    \"\"\" Perform a cross-validation and returns the predictions. \n",
    "    Use a scaler to scale the features to mean 0, standard deviation 1.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    design_matrix: (n_samples, n_features) np.array\n",
    "        Design matrix for the experiment.\n",
    "    labels: (n_samples, ) np.array\n",
    "        Vector of labels.\n",
    "    classifier:  Regressor instance; must have the following methods:\n",
    "        - fit(X, y) to train the regressor on the data X, y\n",
    "        - predict_proba(X) to apply the trained regressor to the data X and return predicted values\n",
    "    cv_folds: sklearn cross-validation object\n",
    "        Cross-validation iterator.\n",
    "        \n",
    "    Return:\n",
    "    -------\n",
    "    pred: (n_samples, ) np.array\n",
    "        Vectors of predictions (same order as labels).\n",
    "    \"\"\"\n",
    "    \n",
    "    pred = np.zeros(labels.shape)\n",
    "    for tr, te in cv_folds:\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        Xtr = scaler.fit_transform(design_matrix[tr,:])\n",
    "        ytr =  labels[tr]\n",
    "        Xte = scaler.transform(design_matrix[te,:])\n",
    "        regressor.fit(Xtr, ytr)\n",
    "        pred[te] = (regressor.predict(Xte))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$\\DeclareMathOperator*{\\argmin}{argmin}$\n",
    "\n",
    "## Bonus 1.1 L2-regularized linear regression (Ridge)\n",
    "Ridge regression shrinks the regression coefficients by imposing a penalty\n",
    "on their size. The ridge coefficients minimize a penalized residual sum of squares,\n",
    "\n",
    "$$\\begin{matrix}\n",
    "\\hat{\\beta}_{ridge} = \\argmin_{\\beta}(y-X\\beta)^T(y-X\\beta) , \\\\\n",
    "subject\\ to\\ \\sum^p_{j=1}\\beta_j^2\\leq t\n",
    "\\end{matrix}$$\n",
    "\n",
    "Notice that the intercept $\\beta_0$ has been left out of the penalty term. Penalization of the intercept would make the  procedure depend on the origin chosen for Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "(Discussion on laplacian.)\n",
    "$$ \\hat{\\beta}_{ridge} = \\argmin_{\\beta}{(y-X\\beta)^T(y-X\\beta) + \\lambda \\sum_{j=1}^p\\beta_j^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** Question: ** use the [scikit learn implementation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) to compute the cross validated mean squared error on the wine-quality dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, metrics\n",
    "\n",
    "np.random.seed(5)\n",
    "regr_ridge = # TODO\n",
    "ypred_ridge = cross_validate_regr(X_regr, y_regr, regr_ridge, folds_regr)\n",
    "print(\"RMSE: %.3f\" % np.sqrt(metrics.mean_squared_error(y_regr, ypred_ridge)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Setting the $\\alpha$ parameter\n",
    "\n",
    "__Question:__ What does the $\\alpha$ parameter correspond to? See the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge) for help.\n",
    "\n",
    "__Question:__ Use GridSearchCV to optimize $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#TO DO\n",
    "param_grid = {'alpha': np.logspace(-3, 3, 6)}\n",
    "regr_ridge_opt = GridSearchCV(#TODO\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Question** What criterion is used to chose the optimal alpha? See the [documentation](http://scikit-learn.org/0.17/modules/generated/sklearn.grid_search.GridSearchCV.html#sklearn.grid_search.GridSearchCV). Try changing this [criterion](http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "regr_ridge_opt = GridSearchCV(linear_model.Ridge(), param_grid, cv=folds_regr, scoring=#TODO\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Question** Compute the cross-validated predictions of the Ridge Regression with optimized alpha parameter on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "ypred_ridge_opt = regr_ridge_opt.fit(X_regr, y_regr)\n",
    "print('param=', regr_ridge_opt.best_params_, 'RMSE=', np.sqrt(-1*regr_ridge_opt.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Note also that best_score is the mean cross-validated score of the best_estimator although we were computing before the mse over all samples in one go by saving the predictions on each fold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Question** Compute the _Nested_Â cross-validated predictions of the Ridge Regression (with and without standardization) with optimized C parameter on our data. Discuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "regr_ridge_opt = GridSearchCV(linear_model.Ridge(), param_grid, scoring=# TODO)\n",
    "ypred_ridge_opt = cross_validate_regr(# TODO)\n",
    "print(\"without scaling:\", metrics.mean_squared_error(y_regr, ypred_ridge_opt))\n",
    "\n",
    "np.random.seed(5)\n",
    "regr_ridge_stand_opt = GridSearchCV(linear_model.Ridge(), param_grid, scoring=#TODO)\n",
    "ypred_ridge_stand_opt = cross_validate_regr_with_scaling(# TODO)\n",
    "print(\"with scaling:\", metrics.mean_squared_error(y_regr,ypred_ridge_stand_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Effect of regularization\n",
    "What is the effect of L2 regularizaton on the learned weigths ?\n",
    "** Question: ** plot the distribution of the learned weigths. Discuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.add_subplot(121)\n",
    "\n",
    "ridge_weights = # TODO\n",
    "number_of_weights = # TODO\n",
    "\n",
    "ax.plot(range(number_of_weights), ridge_weights, \n",
    "         color='blue', marker='+', linestyle='')\n",
    "ax.set_xlabel('Features', fontsize=16)\n",
    "ax.set_ylabel('Weights', fontsize=16)\n",
    "ax.set_title('Ridge regression weights\\n(without standardization)', fontsize=16)\n",
    "ax.set_xlim([0, X_regr.shape[1]])\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "ridge_weights = # TODO\n",
    "\n",
    "ax.plot(range(number_of_weights), ridge_weights, \n",
    "         color='blue', marker='+', linestyle='')\n",
    "ax.set_xlabel('Features', fontsize=16)\n",
    "ax.set_ylabel('Weights', fontsize=16)\n",
    "ax.set_title('Ridge regression weights\\n(with standardization)', fontsize=16)\n",
    "ax.set_xlim([0, X_regr.shape[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Bonus 1.2 L1-regularized linear regression (Lasso)\n",
    "The lasso estimate is defined by\n",
    "\n",
    "$$\\begin{matrix}\n",
    "\\hat{\\beta}_{ridge} = \\argmin_{\\beta}(y-X\\beta)^T(y-X\\beta) , \\\\\n",
    "subject\\ to\\ \\sum^p_{j=1}|\\beta_j|\\leq t\n",
    "\\end{matrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can also write the lasso problem in the equivalent Lagrangian form\n",
    "    $$ \\hat{\\beta}_{ridge} = \\argmin_{\\beta}{(y-X\\beta)^T(y-X\\beta) + \\lambda \\sum_{j=1}^p|\\beta_j|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** Question: ** use the [scikit learn implementation]() to get the cross validated mean suared error and try to vary the $\\alpha$ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "np.random.seed(5)\n",
    "regr_lasso = # TODO\n",
    "ypred_lasso = cross_validate_regr(X_regr, y_regr, regr_lasso, folds_regr)\n",
    "print(metrics.mean_squared_error(y_regr, ypred_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** Question: ** Compute the best (by optimizing alpha) nested cross validation performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'alpha': np.logspace(-4, 4, 9)}\n",
    "\n",
    "regr_lasso_opt = GridSearchCV(linear_model.Lasso(), param_grid)\n",
    "ypred_lasso_opt = cross_validate_regr(X_regr, y_regr, regr_lasso_opt, folds_regr)\n",
    "print(\"without standardization; RMSE: \", np.sqrt(metrics.mean_squared_error(y_regr,\n",
    "                                                                            ypred_lasso_opt)), \n",
    "      '; alpha: ', regr_lasso_opt.best_params_['alpha'])\n",
    "     \n",
    "regr_lasso_stand_opt = GridSearchCV(linear_model.Lasso(), param_grid)\n",
    "ypred_lasso_stand_opt = cross_validate_regr_with_scaling(X_regr, y_regr, regr_lasso_stand_opt, folds_regr)\n",
    "print(\"with standardization; RMSE: \", np.sqrt(metrics.mean_squared_error(y_regr,\n",
    "                                                                         ypred_lasso_stand_opt)), \n",
    "      '; alpha: ', regr_lasso_stand_opt.best_params_['alpha'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Effect of regularization\n",
    "What is the effect of L1 regularizaton on the learned weigths ?\n",
    "** Question: ** plot the distribution of the learned weigths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax = fig.add_subplot(121)\n",
    "\n",
    "lasso_weights = # TODO\n",
    "number_of_weights = # TODO\n",
    "\n",
    "ax.plot(range(number_of_weights), lasso_weights, \n",
    "         color='blue', marker='+', linestyle='')\n",
    "ax.set_xlabel('Features', fontsize=16)\n",
    "ax.set_ylabel('Weights', fontsize=16)\n",
    "ax.set_title('Lasso regression weights\\n(without standardization)', fontsize=16)\n",
    "ax.set_xlim([0, X_regr.shape[1]])\n",
    "print(\"Without standardization, indices of zero weigths\", np.where(lasso_weights==0))\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "lasso_weights = regr_lasso_stand_opt.best_estimator_.coef_\n",
    "\n",
    "ax.plot(range(number_of_weights), lasso_weights, \n",
    "         color='blue', marker='+', linestyle='')\n",
    "ax.set_xlabel('Features', fontsize=16)\n",
    "ax.set_ylabel('Weights', fontsize=16)\n",
    "ax.set_title('Lasso regression weights\\n(with standardization)', fontsize=16)\n",
    "ax.set_xlim([0, X_regr.shape[1]])\n",
    "print(\"With standardization, indices of zero weigths\", np.where(lasso_weights==0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Bonus 2. Implementation of the regularized regression and classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Bonus 2.0 Gradient Descent\n",
    "Recall the gradient descent class we used in the previous lab. To be able to reuse it, include it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class GradientDescentOptimizer():\n",
    "    \"\"\" Class for optimization by gradient descent.\n",
    "    \n",
    "    Attributes:\n",
    "    -----------\n",
    "    f: function\n",
    "        the function to optimize\n",
    "    fprime: function \n",
    "        the gradient of the function to optimize\n",
    "    beta: np.array\n",
    "        the point where the function is currently being evaluated\n",
    "    lr: float\n",
    "        the learning rate\n",
    "    fx: float\n",
    "        the current function value\n",
    "    fgx: np.array\n",
    "        the current gradient value\n",
    "    beta_history: list of np.array\n",
    "        the list of all points where f has been evaluated\n",
    "    \"\"\"\n",
    "    def __init__(self, f, fprime, start, lr=1e-1):\n",
    "        \"\"\"     \n",
    "        Parameters:\n",
    "        -----------\n",
    "        f: function\n",
    "            the function to optimize \n",
    "            Yes, we can pass functions as parameters! To call f within the code, use f followed \n",
    "            by its arguments enclosed between parentheses, as you would normally do: f(x)\n",
    "        fprime: function\n",
    "            the function's gradient\n",
    "        start: np.array\n",
    "            the starting point, at which we begin our search\n",
    "        lr: float\n",
    "            the learning rate\n",
    "        \"\"\"\n",
    "        # Store the parameters as attributes\n",
    "        self.f      = f\n",
    "        self.fprime = fprime\n",
    "        self.beta   = start\n",
    "        self.lr     = lr\n",
    "        # Save history\n",
    "        self.beta_history = [start]\n",
    "          \n",
    "    def compute_fprime(self):\n",
    "        \"\"\" Compute the value of the gradient of f for our current point. \n",
    "        Update self.fgx accordingly.\n",
    "        \"\"\"\n",
    "        self.fgx    = self.fprime(self.beta)\n",
    "    \n",
    "    def step(self):\n",
    "        \"\"\" Take a gradient descent step. \n",
    "        Upgrade self.beta accordingly. \n",
    "        \"\"\"\n",
    "        # Take a gradient descent step.\n",
    "        self.compute_fprime()\n",
    "        d_beta    = -1*self.lr*self.fgx\n",
    "        self.beta = self.beta + d_beta\n",
    "        \n",
    "    def optimize(self, max_iter=1000):\n",
    "        \"\"\"Use the gradient descent optimiser to optimise f.\n",
    "        Update self.f_history and self.beta_history accordingly.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        max_iter: int\n",
    "            Maximum number of iterations.        \n",
    "        \"\"\"\n",
    "        it = 0\n",
    "        while it < max_iter:\n",
    "            self.step()\n",
    "            it = it + 1\n",
    "            # Update history. \n",
    "            self.beta_history += [self.beta]\n",
    "            \n",
    "    def print_result(self):\n",
    "        \"\"\" Print out result once optimization is complete.        \n",
    "        \"\"\"\n",
    "        sys.stdout.write(\" === Result ===\\n\")\n",
    "        sys.stdout.write(\"Best beta found: \" + str(self.beta) +'\\n')\n",
    "        sys.stdout.write(\"f(best beta) = \" + str(self.f(self.beta)) + '\\n')\n",
    "        sys.stdout.write(\"f\\'(best beta) = \" + str(self.fprime(self.beta)) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$\\DeclareMathOperator*{\\argmin}{argmin}$\n",
    "\n",
    "## Bonus  2.1 L2-regularized linear regression (Ridge)\n",
    "Ridge regression shrinks the regression coefficients by imposing a penalty\n",
    "on their size. The ridge coefficients minimize a penalized residual sum of squares,\n",
    "\n",
    "$$\\begin{matrix}\n",
    "\\hat{\\beta}_{ridge} = \\argmin_{\\beta}(y-X\\beta)^T(y-X\\beta) , \\\\\n",
    "subject\\ to\\ \\sum^p_{j=1}\\beta_j^2\\leq t\n",
    "\\end{matrix}$$\n",
    "\n",
    "Notice that the intercept $\\beta_0$ has been left out of the penalty term. Penalization of the intercept would make the  procedure depend on the origin chosen for Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This problem is equivalent to:\n",
    "$$ \\hat{\\beta}_{ridge} = \\argmin_{\\beta}{(y-X\\beta)^T(y-X\\beta) + \\lambda \\sum_{j=1}^p\\beta_j^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Differentiating with respect to $\\beta$ we obtain $$\\frac{\\partial{RSS\\_ridge}}{\\partial{\\beta}} = -2X^T(y-X\\beta) + 2\\lambda\\beta_j $$\n",
    "\n",
    "If $X^TX$ is inversible, we obtain a unique solution by setting the first derivative to 0.\n",
    "$$\\hat{\\beta} = (X^TX+\\lambda\\mathbf{I})^{-1}X^Ty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The solution adds a positive constant to the diagonal of $X^TX$ before inversion. Notice that this makes the problem nonsingular, even if $X^TX$ is not of full rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "class RidgeRegr():\n",
    "    \"\"\" Class for least-squares linear regression:\n",
    "    Parameters:\n",
    "    -----------\n",
    "    lambda_: float,\n",
    "        regularization parameter.\n",
    "    fit_intercept: bool,\n",
    "        add or not an intercept to the model.\n",
    "    \n",
    "    Attributes:\n",
    "    -----------\n",
    "    coef_: 1-dimensional np.array\n",
    "        coefficients of the linear regression (beta)\n",
    "    \"\"\"\n",
    "    def __init__(self,lambda_=1.0,fit_intercept=True):\n",
    "        self.coef_ = None\n",
    "        self.lambda_ = lambda_\n",
    "        self.fit_intercept = fit_intercept\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        \"\"\" Fit the data (X, y).\n",
    "    \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: (num_samples, num_features) np.array\n",
    "            Design matrix\n",
    "        y: (num_sampes, ) np.array\n",
    "            Output vector\n",
    "        \n",
    "        Note:\n",
    "        -----\n",
    "        Updates self.coef_\n",
    "        \"\"\"\n",
    "        if self.fit_intercept==True:\n",
    "            X = np.concatenate((X,np.ones((X.shape[0],1))),axis=1)\n",
    "        \n",
    "        self.coef_ = # TODO\n",
    "        \n",
    "    def predict(self,X):\n",
    "        \"\"\" Make predictions for data X.\n",
    "    \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: (num_samples, num_features) np.array\n",
    "            Design matrix\n",
    "        \n",
    "        Returns:\n",
    "        -----\n",
    "        y_pred: (num_samples, ) np.array\n",
    "            Predictions\n",
    "        \"\"\"\n",
    "        if self.fit_intercept==True:\n",
    "            X = np.concatenate((X,np.ones((X.shape[0],1))), axis=1)\n",
    "        return # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The ridge solutions are not equivariant under scaling of the inputs, and so one normally standardizes the inputs before solving. Notice that in that case $\\hat{\\beta}_{0}$ is $\\bar{y}$.\n",
    "\n",
    "**Question** Use the cross_validate_with_scaling method to cross-validate the logistic regression on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "regr_ridge = # TODO\n",
    "ypred_ridge_scaled = cross_validate_regr_with_scaling(X_regr, y_regr, regr_ridge, folds_regr)\n",
    "print(\"RMSE: %.3f\" % np.sqrt(metrics.mean_squared_error(y_regr, ypred_ridge_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** Question: ** Implement the sequential version of ridge regression. Complete the class below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "\n",
    "class seq_RidgeRegr():\n",
    "    \"\"\" Class for sequential Ridge regression:\n",
    "    Parameters:\n",
    "    -----------\n",
    "    lambda_: float,\n",
    "        regularization parameter.\n",
    "    \n",
    "    Attributes:\n",
    "    -----------\n",
    "    coef_: 1-dimensional np.array\n",
    "        coefficients of the linear regression (beta)\n",
    "    \"\"\"\n",
    "    def __init__(self,lambda_=1.0):\n",
    "        self.coef_ = None\n",
    "        self.lambda_ = lambda_\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        \"\"\" Fit the data (X, y).\n",
    "    \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: (num_samples, num_features) np.array\n",
    "            Design matrix\n",
    "        y: (num_sampes, ) np.array\n",
    "            Output vector\n",
    "        \n",
    "        Note:\n",
    "        -----\n",
    "        Updates self.coef_\n",
    "        \"\"\"\n",
    "        X_aug = np.ones((X.shape[0], X.shape[1] + 1))\n",
    "        X_aug[:X.shape[0], :X.shape[1]] = X\n",
    "        \n",
    "        # Get the initial parameter vector. \n",
    "        self.coef_ =  # TODO\n",
    "        \n",
    "        def f_loss(beta):\n",
    "            \"\"\" Returns the loss function.        \n",
    "            \"\"\"\n",
    "            beta   = np.reshape(beta, [-1,1])\n",
    "            phi    = np.squeeze(np.dot(X_aug, beta))\n",
    "            loss   = # TODO\n",
    "            return loss\n",
    "        \n",
    "        def fprime_loss(beta):\n",
    "            \"\"\" Returns the gradient of f_ls at beta.\n",
    "            IMPORTANT:  The output should have the same shape as beta,\n",
    "            otherwise our optimiser will not work.\n",
    "            \"\"\"\n",
    "            phi    = np.dot(X_aug, beta.reshape([-1,1]))\n",
    "            gradient = # TODO\n",
    "            return gradient\n",
    "        \n",
    "        # Initialize the GradientDescentOptimizer\n",
    "        self.gd    = GradientDescentOptimizer(f_loss, fprime_loss, self.coef_, lr=1*1e-2)\n",
    "        # Optimize\n",
    "        self.gd.optimize()\n",
    "        # Retrieve the result\n",
    "        self.coef_ = self.gd.beta\n",
    "        \n",
    "    def predict(self,X):\n",
    "        \"\"\" Make predictions for data X.\n",
    "    \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: (num_samples, num_features) np.array\n",
    "            Design matrix\n",
    "        \n",
    "        Returns:\n",
    "        -----\n",
    "        y_pred: (num_samples, ) np.array\n",
    "            Predictions\n",
    "        \"\"\"\n",
    "        X_aug = np.ones((X.shape[0], X.shape[1] + 1))\n",
    "        X_aug[:X.shape[0], :X.shape[1]] = X\n",
    "        return # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Now apply to the data\n",
    "np.random.seed(5)\n",
    "regr_seqridge = # TODO\n",
    "ypred_ridge_scaled = cross_validate_regr_with_scaling(X_regr, y_regr, regr_seqridge, folds_regr)    # TODO\n",
    "print(\"RMSE: %.3f\" % np.sqrt(metrics.mean_squared_error(y_regr,ypred_ridge_scaled)))\n",
    "plt.plot([regr_seqridge.gd.f(x) for x in regr_seqridge.gd.beta_history], 'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "** Question: ** compare with the performance obtained with scikit learn implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Bonus 2.2 L1-regularized linear regression (Lasso)\n",
    "The lasso estimate is defined by\n",
    "\n",
    "$$\\begin{matrix}\n",
    "\\hat{\\beta}_{ridge} = \\argmin_{\\beta}(y-X\\beta)^T(y-X\\beta) , \\\\\n",
    "subject\\ to\\ \\sum^p_{j=1}|\\beta_j|\\leq t\n",
    "\\end{matrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can also write the lasso problem in the equivalent Lagrangian form\n",
    "    $$ \\hat{\\beta}_{ridge} = \\argmin_{\\beta}{(y-X\\beta)^T(y-X\\beta) + \\lambda \\sum_{j=1}^p|\\beta_j|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The constraint makes the solutions nonlinear in the $y_i$ , and there is no closed form expression as in ridge regression. Computing the lasso solution is a quadratic programming problem. \n",
    "\n",
    "The Lasso regularizer is not differentiable everywhere - it is not differentiable at $\\beta = (0, 0, \\ldots, 0)$. Thus we should not use gradient descent to optimise it. However, let us try to use it anyway and see what happens. We will see later why this is not appropriate. Complete the class given below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "\n",
    "class seq_Lasso():\n",
    "    \"\"\" Class for sequential Lasso:\n",
    "    Parameters:\n",
    "    -----------\n",
    "    lambda_: float,\n",
    "        regularization parameter.\n",
    "    \n",
    "    Attributes:\n",
    "    -----------\n",
    "    coef_: 1-dimensional np.array\n",
    "        coefficients of the linear regression (beta)\n",
    "    \"\"\"\n",
    "    def __init__(self,lambda_=1.0):\n",
    "        self.coef_ = None\n",
    "        self.lambda_ = lambda_\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        \"\"\" Fit the data (X, y).\n",
    "    \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: (num_samples, num_features) np.array\n",
    "            Design matrix\n",
    "        y: (num_sampes, ) np.array\n",
    "            Output vector\n",
    "        \n",
    "        Note:\n",
    "        -----\n",
    "        Updates self.coef_\n",
    "        \"\"\"\n",
    "        X_aug = np.ones((X.shape[0], X.shape[1] + 1))\n",
    "        X_aug[:X.shape[0], :X.shape[1]] = X\n",
    "        self.coef_ = np.random.normal(size=(X_aug.shape[1],), loc=0.0, scale=1.0)\n",
    "        \n",
    "        # Define the loss function. Include np.sum(np.abs(beta)) \n",
    "        #   to incorporate L1-regularisation.\n",
    "        def f_loss(beta):\n",
    "            # TODO\n",
    "            return loss\n",
    "        \n",
    "        # Define the gradient of the loss function at a given point. \n",
    "        def fprime_loss(beta):\n",
    "            # Define the gradient of the loss function. \n",
    "            # Ensure that you return an array of the same shape as beta,\n",
    "            #    otherwise the optimisation will not work!\n",
    "            # TODO\n",
    "            return gradient\n",
    "        \n",
    "        # Initialise the GradientDescentOptimizer. \n",
    "        self.gd = GradientDescentOptimizer(f_loss, fprime_loss, self.coef_, lr=1e-1)\n",
    "        # Optimize\n",
    "        self.gd.optimize()\n",
    "        # Retrieve the best set of parameters found by the optimiser\n",
    "        self.coef_ = self.gd.beta\n",
    "            \n",
    "    def predict(self,X):\n",
    "        \"\"\" Make predictions for data X.\n",
    "    \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: (num_samples, num_features) np.array\n",
    "            Design matrix\n",
    "        \n",
    "        Returns:\n",
    "        -----\n",
    "        y_pred: (num_samples, ) np.array\n",
    "            Predictions\n",
    "        \"\"\"\n",
    "        # Again, augment the data matrix first. \n",
    "        X_aug = np.ones((X.shape[0], X.shape[1] + 1))\n",
    "        X_aug[:X.shape[0], :X.shape[1]] = X\n",
    "        # Make a prediction.\n",
    "        return # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Now apply it to the data\n",
    "# Use cross_validate_regr_with_scaling.\n",
    "np.random.seed(5)\n",
    "regr_lasso = # TODO\n",
    "ypred_lasso = cross_validate_regr_with_scaling(X_regr, y_regr, regr_lasso, folds_regr)\n",
    "print(metrics.mean_squared_error(y_regr, ypred_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Question: ** compare with the performance obtained with the scikit learn implementation. Look at the learned weights and discuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(regr_lasso.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "__Question:__ Do you observe the expected behavior? If not, can you think of an explanation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Bonus 2.3 L1-Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\" Sigmoid function.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x: np.array\n",
    "        input variables\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    r: np.array of same dimension as x\n",
    "        outputs\n",
    "    \"\"\"\n",
    "    # Truncate the very large and very small values of x to avoid overflowing the exponential.\n",
    "    x[np.where(x > 7e2)] = 7e2\n",
    "    x[np.where(x < -7e2)] = -7e2\n",
    "    \n",
    "    # Compute the sigmoid\n",
    "    r = 1. / (1 + np.exp(-1*x))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Question** Finish implementing the following class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LogisticRegression_l1reg():\n",
    "    \"\"\" Class for sequential LA-regularized logistic regression:\n",
    "    Parameters:\n",
    "    -----------\n",
    "    lambda_: float,\n",
    "        regularization parameter.\n",
    "        \n",
    "    Attributes:\n",
    "    -----------\n",
    "    coef_: 1-dimensional np.array\n",
    "        coefficients of the linear regression (beta)\n",
    "    classes_: list\n",
    "        list of class labels\n",
    "    \"\"\"\n",
    "    def __init__(self, lambda_=1.0):\n",
    "        self.coef_ = None\n",
    "        self.lambda_ = lambda_\n",
    "        self.classes_ = [0,1] # only for binary classification\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        \"\"\" Fit the data (X, y).\n",
    "    \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: (num_samples, num_features) np.array\n",
    "            Design matrix\n",
    "        y: (num_sampes, ) np.array\n",
    "            Output vector\n",
    "        \n",
    "        Note:\n",
    "        -----\n",
    "        Updates self.coef_\n",
    "        \"\"\"\n",
    "        n_points = X.shape[0]\n",
    "        n_vars   = X.shape[1]\n",
    "        X_aug = np.ones((n_points, n_vars + 1))\n",
    "        X_aug[:n_points, :n_vars] = X\n",
    "        coef_ = np.random.normal(size=(X_aug.shape[1],), loc=0.0, scale=1.0)\n",
    "        \n",
    "        cl_ids0 = np.where(y == 0)[0]\n",
    "        cl_ids1 = np.where(y == 1)[0]\n",
    "        def f_loss(beta):\n",
    "            phi_0 = sigmoid(np.dot(X_aug[cl_ids0,:], beta.reshape([-1,1])).squeeze())\n",
    "            phi_1 = sigmoid(np.dot(X_aug[cl_ids1,:], beta.reshape([-1,1])).squeeze())\n",
    "            loss  = # TODO\n",
    "            return loss\n",
    "        \n",
    "        def fprime_loss(beta):\n",
    "            # IMPORTANT: The gradient should have the same shape as beta,\n",
    "            #    otherwise our optimiser will not work.\n",
    "            phi       = # TODO\n",
    "            gradient  = # TODO\n",
    "            return gradient\n",
    "        \n",
    "        gd = GradientDescentOptimizer(f_loss, fprime_loss, coef_, lr=1e-1)\n",
    "        gd.optimize()\n",
    "        self.coef_ = gd.beta\n",
    "        \n",
    "    def predict_proba(self,X):\n",
    "        \"\"\" Make probabilistic predictions for data X.\n",
    "    \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X: (num_samples, num_features) np.array\n",
    "            Design matrix\n",
    "        \n",
    "        Returns:\n",
    "        -----\n",
    "        y_pred: (num_samples, ) np.array\n",
    "            Predictions (probabilities of belonging to class 1)\n",
    "        \"\"\"\n",
    "        X_aug = np.ones((X.shape[0], X.shape[1] + 1))\n",
    "        X_aug[:X.shape[0], :X.shape[1]] = X\n",
    "        phi   = sigmoid(np.dot(X_aug, self.coef_.reshape([-1,1])).squeeze())\n",
    "        \n",
    "        pred  = # TODO\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You'll find the utility functions for cross-validation in a classification setting from Lab 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## make folds\n",
    "from sklearn import model_selection\n",
    "skf = model_selection.StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(X_clf, y_clf)\n",
    "folds_clf = [(tr,te) for (tr,te) in skf.split(X_clf, y_clf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# let's redefine the cross-validation procedure\n",
    "def cross_validate_clf(design_matrix, labels, classifier, cv_folds):\n",
    "    \"\"\" Perform a cross-validation and returns the predictions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    design_matrix: (n_samples, n_features) np.array\n",
    "        Design matrix for the experiment.\n",
    "    labels: (n_samples, ) np.array\n",
    "        Vector of labels.\n",
    "    classifier:  sklearn classifier object\n",
    "        Classifier instance; must have the following methods:\n",
    "        - fit(X, y) to train the classifier on the data X, y\n",
    "        - predict_proba(X) to apply the trained classifier to the data X and return probability estimates \n",
    "    cv_folds: sklearn cross-validation object\n",
    "        Cross-validation iterator.\n",
    "        \n",
    "    Return:\n",
    "    -------\n",
    "    pred: (n_samples, ) np.array\n",
    "        Vectors of predictions (same order as labels).\n",
    "    \"\"\"\n",
    "    pred = np.zeros(labels.shape)\n",
    "    for tr, te in cv_folds:\n",
    "        classifier.fit(design_matrix[tr,:], labels[tr])\n",
    "        pred[te] = (classifier.predict_proba(design_matrix[te,:]))[:,list(classifier.classes_).index(1)]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# let's redefine the cross-validation procedure with standardization\n",
    "def cross_validate_clf_with_scaling(design_matrix, labels, classifier, cv_folds):\n",
    "    \"\"\" Perform a cross-validation and returns the predictions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    design_matrix: (n_samples, n_features) np.array\n",
    "        Design matrix for the experiment.\n",
    "    labels: (n_samples, ) np.array\n",
    "        Vector of labels.\n",
    "    classifier:  sklearn classifier object\n",
    "        Classifier instance; must have the following methods:\n",
    "        - fit(X, y) to train the classifier on the data X, y\n",
    "        - predict_proba(X) to apply the trained classifier to the data X and return probability estimates \n",
    "    cv_folds: sklearn cross-validation object\n",
    "        Cross-validation iterator.\n",
    "        \n",
    "    Return:\n",
    "    -------\n",
    "    pred: (n_samples, ) np.array\n",
    "        Vectors of predictions (same order as labels).\n",
    "    \"\"\"\n",
    "    pred = np.zeros(labels.shape)\n",
    "    for tr, te in cv_folds:\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        Xtr = scaler.fit_transform(design_matrix[tr,:])\n",
    "        ytr = labels[tr]\n",
    "        Xte = scaler.transform(design_matrix[te,:])\n",
    "        classifier.fit(Xtr, ytr)\n",
    "        pred[te] = (classifier.predict_proba(Xte))[:,list(classifier.classes_).index(1)]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Question** compute the cross-validated predictions of the l1-regularized logistic regression with default parameters on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf_logreg_l1reg = # TODO\n",
    "ypred_logreg_l1reg = cross_validate_clf(X_clf, y_clf, clf_logreg_l1reg, folds_clf)\n",
    "print(\"without standardization:\", metrics.accuracy_score(y_clf,np.where(ypred_logreg_l1reg > 0.5, 1, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Question: ** compare with the performance obtained with the scikit learn implementation. Look at the learned weights and discuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Bonus 3. Classification on dimensionality-reduced data\n",
    "Going back to the classification on the ovary vs breast cancer data (Lab 1), we consider here the comparison between classification on projected and original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data/small_Breast_Ovary.csv', sep=\",\")\n",
    "my_data = data.drop(['ID_REF', 'Tissue'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_data = data[['Tissue']]\n",
    "y_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_data = pd.get_dummies(y_data,)\n",
    "y = y_data.values[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "skf = cross_validation.StratifiedKFold(y, 5, shuffle=True, random_state=93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, decomposition\n",
    "\n",
    "X = my_data.values\n",
    "X_scaled = preprocessing.scale(X)\n",
    "\n",
    "pca = decomposition.PCA(n_components=30)\n",
    "X_projected = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.bar(np.arange(30), pca.explained_variance_ratio_)\n",
    "plt.xlim([-1, 29])\n",
    "plt.xlabel(\"Number of PCs\", fontsize=16)\n",
    "plt.ylabel(\"Fraction of variance explained\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for color_name, tissue, tissue_name, index in zip(['blue', 'orange'], [-1, 1], ['breast', 'ovary'],\n",
    "                                                  [(data.Tissue =='Breast').values, \n",
    "                                                   (data.Tissue!='Breast').values]):\n",
    "    plt.scatter(X_projected[index,0], X_projected[index,1], \n",
    "                c=color_name, label=tissue_name)\n",
    "plt.legend(loc=(1.1, 0), fontsize=14)\n",
    "plt.xlabel(\"PC 1\", fontsize=16)\n",
    "plt.ylabel(\"PC 2\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# removing outliers\n",
    "index1 = np.where(X_projected[:,0]<60)\n",
    "index2 = np.where(X_projected[:,1]<40)\n",
    "index = np.intersect1d(index1, index2)\n",
    "\n",
    "X_wo = X[index,:]\n",
    "y_wo = y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for color_name, tissue, tissue_name, index in zip(['blue', 'orange'], [-1, 1], ['breast', 'ovary'],\n",
    "                                                  [(data.Tissue =='Breast').values, \n",
    "                                                   (data.Tissue!='Breast').values]):\n",
    "    X_plot = X_projected[index,:]\n",
    "    X_plot = X_plot[X_plot[:,0]<60,:]\n",
    "    X_plot = X_plot[X_plot[:,1]<40,:]\n",
    "    plt.scatter(X_plot[:,0], X_plot[:,1], c=color_name, label=tissue_name)\n",
    "plt.legend(loc=(1.1, 0), fontsize=14)\n",
    "plt.xlabel(\"PC 1\", fontsize=16)\n",
    "plt.ylabel(\"PC 2\", fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Question:** How many PCs do you think are sufficient to represent your data? What do you expect will happen if you use the projection of the gene expressions on these PCs and run a cross-validation of a classification algorithm? Try it out. Is there a risk of overfitting when you do this? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'penalty':['l1', 'l2'], 'C':[1e-3, 1e-2, 1e-1, 1., 1e1, 1e2, 1e3]}\n",
    "clf = GridSearchCV(linear_model.LogisticRegression(), param_grid, n_jobs=3, cv=skf, scoring='roc_auc')\n",
    "\n",
    "print('trained on original data')\n",
    "clf.fit(X_scaled, y)\n",
    "print(clf.best_params_, clf.best_score_)\n",
    "print(clf.best_params_, np.sort(clf.cv_results_['mean_test_score'])[::-1][0])\n",
    "\n",
    "clf = GridSearchCV(linear_model.LogisticRegression(), param_grid, n_jobs=3, cv=skf, scoring='roc_auc')\n",
    "print('trained on projected data')\n",
    "clf.fit(# TODO\n",
    ")\n",
    "print(clf.best_params_, clf.best_score_)\n",
    "print(clf.best_params_, np.sort(clf.cv_results_['mean_test_score'])[::-1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Using pipelines**\n",
    "\n",
    "In order to combine efficiently and correctly dimentionality reduction and classification, we will use a `sklearn.pipeline` to chain `tranformers` objects (must have a `fit` and a `transform` method) with a final predictor object (must have a `fit` and a `predict` method).\n",
    "\n",
    "This is useful as there is often a fixed sequence of steps in processing the data, for example standardization, feature pre-processing and classification or, feature selection, normalization and classification. By concatenating standardization and classification, pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors.\n",
    "\n",
    "Pipeline has `fit` and `predict` methods to be lunch once on your data to fit the corresponding whole sequence of transfromers and estimator. More interestingly, we will grid search over parameters of all transformers and estimator in the pipeline at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "estimators = [\n",
    "    ('preprocessing', preprocessing.StandardScaler()), \n",
    "    ('reduce_dim', PCA()), \n",
    "    ('clf', linear_model.LogisticRegression())\n",
    "]\n",
    "pipe = Pipeline(estimators)\n",
    "pipe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The estimators of a pipeline are stored as a list in the steps attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pipe.steps[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "and as a dict in named_steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pipe.named_steps['reduce_dim']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Parameters of the estimators in the pipeline can be accessed using the `<estimator>__<parameter>` syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pipe.set_params(clf__C=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Thus, a parameter grid for a pipeline must be implemented as the following.\n",
    "Notice that individual steps may also be replaced as parameters , and non-final steps may be ignored by setting them to `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "C_OPTIONS = np.logspace(-3, 3, 6)\n",
    "\n",
    "param_grid = [\n",
    "              {'preprocessing': [preprocessing.StandardScaler()],\n",
    "              'reduce_dim': [None],\n",
    "              'clf': [linear_model.LogisticRegression()],\n",
    "              'clf__penalty': ['l1', 'l2'],\n",
    "              'clf__C': C_OPTIONS},\n",
    "             \n",
    "              {'preprocessing': [preprocessing.StandardScaler()],\n",
    "              'reduce_dim': [PCA()],\n",
    "              'reduce_dim__n_components': [30, 80, 100, 200, 500],\n",
    "              'clf': [linear_model.LogisticRegression()],\n",
    "              'clf__penalty': ['l1', 'l2'],\n",
    "              'clf__C': C_OPTIONS},\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Â be careful, it may take quite a lot of time if the number of tested models is large.\n",
    "# in such a case, you can reduce the number of tested parameters in \"param_grid\"\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(pipe, cv=skf, n_jobs=3, param_grid=param_grid, scoring='roc_auc')\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot the score \n",
    "data_frame = {name:[] for i in range(len(grid.cv_results_['params'])) for name in grid.cv_results_['params'][i]}\n",
    "data_frame['score'] = []\n",
    "\n",
    "sorted_index_score = np.argsort(grid.cv_results_['mean_test_score'])[::-1]\n",
    "for ind in sorted_index_score:\n",
    "    data_frame['score'].append(grid.cv_results_['mean_test_score'][ind])\n",
    "    for name in data_frame.keys():\n",
    "        if name in grid.cv_results_['params'][ind]:\n",
    "            data_frame[name].append(grid.cv_results_['params'][ind][name])\n",
    "        elif name!='score':\n",
    "            data_frame[name].append(None)\n",
    "    \n",
    "pd.DataFrame(data_frame).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "** Question ** What do you observe? Discuss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
