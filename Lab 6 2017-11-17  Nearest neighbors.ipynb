{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2017-11-17: Nearest Neighbors\n",
    "\n",
    "In this lab, we will apply nearest neighbors classification to the Endometrium vs. Uterus cancer data. For documentation, see:\n",
    "* http://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification; and \n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n",
    "\n",
    "We will implement our own nearest neighbors classifier and compare the results with the in-built classifiers offered by scikit-learn. \n",
    "\n",
    "Let us start by setting up our environment, loading the data, and setting up our cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Load the data as in the previous labs. We will use `small_Endometrium_Uterus.csv` for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# load the endometrium vs. uterus tumor data\n",
    "endometrium_data = pd.read_csv('data/small_Endometrium_Uterus.csv', sep=\",\")  # load data\n",
    "endometrium_data.head(n=5)  # adjust n to view more data\n",
    "\n",
    "# Create the design matrix and target vector\n",
    "X_clf = endometrium_data.drop(['ID_REF', 'Tissue'], axis=1).values\n",
    "y_clf = pd.get_dummies(endometrium_data['Tissue']).values[:,1]\n",
    "\n",
    "print(X_clf.shape)\n",
    "plt.scatter(X_clf[:,0], X_clf[:,1], c=y_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Recall functions we had used to create cross validation folds in the previous labs. Redefine them here. \n",
    "\n",
    "*Note* : We shall call this *m*-fold cross validation, unlike *k*-fold, which we used in our previous labs, to distinguish it from *k*-nearest neighbors classification. This emphasizes that the two parameters are indeed different from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "def stratifiedMFolds(y, num_folds):\n",
    "    kf = model_selection.StratifiedKFold(n_splits=num_folds)\n",
    "    folds_regr = [(tr, te) for (tr, te) in kf.split(np.zeros(y.size), y)]\n",
    "    return folds_regr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now create 10 cross validate folds on the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cv_folds = stratifiedMFolds(y_clf, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Import the previously written cross validation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# let's redefine the cross-validation procedure with standardization\n",
    "from sklearn import preprocessing\n",
    "def cross_validate(design_matrix, labels, regressor, cv_folds):\n",
    "    \"\"\" Perform a cross-validation and returns the predictions. \n",
    "    Use a scaler to scale the features to mean 0, standard deviation 1.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    design_matrix: (n_samples, n_features) np.array\n",
    "        Design matrix for the experiment.\n",
    "    labels: (n_samples, ) np.array\n",
    "        Vector of labels.\n",
    "    classifier:  Regressor instance; must have the following methods:\n",
    "        - fit(X, y) to train the regressor on the data X, y\n",
    "        - predict_proba(X) to apply the trained regressor to the data X and return predicted values\n",
    "    cv_folds: sklearn cross-validation object\n",
    "        Cross-validation iterator.\n",
    "        \n",
    "    Return:\n",
    "    -------\n",
    "    pred: (n_samples, ) np.array\n",
    "        Vectors of predictions (same order as labels).\n",
    "    \"\"\"\n",
    "    \n",
    "    n_classes = np.unique(labels).size\n",
    "    pred = np.zeros((labels.shape[0], n_classes))\n",
    "    for tr, te in cv_folds:\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        Xtr = scaler.fit_transform(design_matrix[tr,:])\n",
    "        ytr =  labels[tr]\n",
    "        Xte = scaler.transform(design_matrix[te,:])\n",
    "        regressor.fit(Xtr, ytr)\n",
    "        pred[te, :] = regressor.predict_proba(Xte)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1. *k*-Nearest Neighbours Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A k-neighbours classifier can be initialised as `knn_clf = sklearn.neighbors.KNeighborsClassifier(n_neighbors=k)`\n",
    "\n",
    "Cross validate 20 *k*-NN classifiers on the loaded datset using `cross_validate`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn import metrics\n",
    "\n",
    "aurocs_clf = []\n",
    "# Create a range of values of k. We will use this throughout the lab.\n",
    "k_range    = range(1,40,2) \n",
    "\n",
    "for k in k_range:\n",
    "    clf    = # TODO \n",
    "    y_pred = # TODO \n",
    "    \n",
    "    fpr, tpr, thresholdss = metrics.roc_curve(y_clf, y_pred[:,1])\n",
    "    aurocs_clf.append(metrics.auc(fpr,tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now plot the AUC as a function of the number of nearest neighbours chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.plot(k_range, aurocs_clf, color='blue')\n",
    "plt.xlabel('Number of nearest neighbours')\n",
    "plt.ylabel('Cross-validated AUC')\n",
    "plt.title('Nearest neighbours classification - cross validated AUC.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Question.** Find the best value for the parameter `n_neighbors` by finding the one that gives the maximum value of AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "best_k = #TODO\n",
    "print k_range[best_k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let us now use `sklearn.model_selection.GridSearchCV` do to the same. The parameter to be cross-validated is the number of nearest neighbours to choose. Use an appropriate list to feed to `GridSearchCV` to find the best value for the nearest neighbours parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "classifier = # TODO\n",
    "# TODO\n",
    "param_grid = # TODO \n",
    "clf_knn_opt = model_selection.GridSearchCV(classifier,  param_grid=param_grid, cv=cv_folds)\n",
    "clf_knn_opt.fit( #TODO,\n",
    "                 # TODO \n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Find the best parameter\n",
    "print clf_knn_opt.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Try choosing different scoring metrics for GridSearchCV, and see how the result changes. You can find scoring metrics [here](http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now compare the performance of the *k*-nearest neighbours classifier with logistic regularisation (both, non-regularised, and regularised)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "clf_logreg_l2 = linear_model.LogisticRegression()\n",
    "logreg_params = {'C':#TODO\n",
    "                \n",
    "clf_logreg_opt = model_selection.GridSearchCV( # TODO,\n",
    "                                               # TODO\n",
    "                                               # TODO\n",
    "                                             )\n",
    "clf_logreg_opt.fit(X_clf, y_clf)\n",
    "ypred_clf_logreg_opt = cross_validate(X_clf, y_clf, clf_logreg_opt.best_estimator_, cv_folds)\n",
    "fpr_clf_logreg_opt, tpr_clf_logreg_opt, thresh = metrics.roc_curve(y_clf, ypred_clf_logreg_opt[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf_logreg = linear_model.LogisticRegression(C=1e12)\n",
    "ypred_clf_logreg = # TODO\n",
    "fpr_clf_logreg, tpr_clf_logreg, thresh = # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ypred_clf_knn_opt = # TODO\n",
    "fpr_clf_knn_opt, tpr_clf_knn_opt, thresh = # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "logreg_l2_h,  = plt.plot(fpr_clf_logreg_opt, tpr_clf_logreg_opt, 'b-')\n",
    "logreg_h,     = plt.plot(fpr_clf_logreg, tpr_clf_logreg, 'g-')\n",
    "knn_h,        = plt.plot(fpr_clf_knn_opt, tpr_clf_knn_opt, 'r-')\n",
    "logreg_l2_auc    = metrics.auc(fpr_clf_logreg_opt, tpr_clf_logreg_opt)\n",
    "logreg_auc = metrics.auc(fpr_clf_logreg, tpr_clf_logreg)\n",
    "knn_auc       = metrics.auc(fpr_clf_knn_opt, tpr_clf_knn_opt)\n",
    "\n",
    "\n",
    "logreg_legend    = 'LogisticRegression. AUC=%.2f' %(logreg_auc)\n",
    "logreg_l2_legend = 'Regularised LogisticRegression. AUC=%.2f' %(logreg_l2_auc)\n",
    "knn_legend       = 'KNeighborsClassifier. AUC=%.2f' %(knn_auc)\n",
    "plt.legend([logreg_h, logreg_l2_h, knn_h], [logreg_legend, logreg_l2_legend, knn_legend])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves comparison for logistic regression and k-nearest neighbours classifier.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Setting the distance measure**. You will notice that *k*-nearest neighbours classifiers measure distances between points to determine similarity. By default, we use the Euclidean distance metric. Often, using other distance metrics can prove to be helpful. Try to change the distance metric used here by passing it as an argument to the declaration of the classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "classifiers = {}            \n",
    "y_preds     = {}            \n",
    "# Fix a set of distance metrics to use\n",
    "d_metrics = ['euclidean', 'cityblock', 'correlation' , 'cosine']\n",
    "aurocs    = {}      \n",
    "\n",
    "for m in d_metrics:\n",
    "    aurocs[m] = []          \n",
    "    for k in k_range: \n",
    "        classifiers[m] = # TODO. Initialise a kNN classifier with n_neighbors=k and metric=m\n",
    "        y_preds[m]     = # TODO. Cross validate on the data. Use cross_validate\n",
    "    \n",
    "        fpr, tpr, thresholds = # TODO.\n",
    "        auc                  = # TODO.\n",
    "        aurocs[m].append(auc)     \n",
    "        \n",
    "        print 'Metric = %-12s | k = %3d | AUC = %.3f.' %(m, k, aurocs[m][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now plot ROC curves for all the metrics together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f = plt.figure()\n",
    "handles = [[] for i in range(len(d_metrics))]\n",
    "colours = ['blue', 'red', 'black', 'yellow'] \n",
    "for i in range(len(d_metrics)):              \n",
    "    handles[i], = plt.plot(k_range, aurocs[d_metrics[i]], color=colours[i])  # SOLUTION\n",
    "\n",
    "plt.xlabel('Number of nearest neighbors', fontsize=16)\n",
    "plt.ylabel('Cross-validated AUC', fontsize=16)\n",
    "plt.title('Nearest neighbors classification', fontsize=16)\n",
    "plt.legend(handles, d_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2. Kaggle Challenge.\n",
    "\n",
    "Cross-validate a *k*-NN on the challenge's data and submit to the leaderboard. What scoring criterion are you using? How does the leaderboard performance compare to your cross-validated performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3. Bonus: Implementating *k*-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this section, you can write your own nearest neighbours classifier.\n",
    "\n",
    "Create a class to define a *k*-nearest neighbor classifier. The class must define certain functions (according to convention) - `fit`, `predict`, and `predict_proba`. `fit` takes as argument some data, and fits the classifier to it. `predict` and `predict_proba` also take some data, but predict class labels on this data based on the fitted classifier. These definitions are described below. `predict_proba` assigns a probability vector for each test point, representing its confidence in that test point belonging to each of the classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "class kNNClassifier:\n",
    "    # To start, determine what members this class must have. \n",
    "    # Recall that Python does not have public and private class members. \n",
    "    \n",
    "    # Define the __init__ function. \n",
    "    def __init__(self, k=3):\n",
    "        self.k    = k\n",
    "        self.data = None\n",
    "    \n",
    "    # Define the fit function. You must also use an appropriate function prototype. \n",
    "    def fit(self, X, y):\n",
    "        self.data      = X\n",
    "        \n",
    "        # Fix class labels so that they are in [0, num_labels].\n",
    "        self.target    = y\n",
    "        self.classes   = np.unique(y)\n",
    "        self.n_classes = self.classes.size\n",
    "        d              = {}\n",
    "        for i in range(self.n_classes):\n",
    "            d[self.classes[i]] = i\n",
    "        # Now use self._target as a mapping.\n",
    "        self._target   = np.array([d[i] for i in self.target], dtype=np.int)  \n",
    "    \n",
    "    # Define the predict_proba function. You must use an appropriate function prototype. \n",
    "    def predict_proba(self, X):        \n",
    "        n_test, n_vars  = X.shape\n",
    "        n_train, n_vars = self.data.shape\n",
    "                \n",
    "        dists = # TODO: Find pairwise distances between each point in X and each point in self.data\n",
    "        top_k = # TODO: For each point in X, sort these distance and retrieve self.k closest points from self.data\n",
    "        # TODO: For each point in X, compute probabilities of it belonging to each class. The probability\n",
    "        #       of a point belonging to a class is simply the number of neighbours of that class in the top-k \n",
    "        #       divided by k.\n",
    "        return probs\n",
    "    \n",
    "    # Define the predict function. You must also use an appropriate function prototype. \n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        return self.classes[np.argmax(probs, axis=1)]\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now that we have the class defined, we can use it. Define an instance of the `kNNClassifier` below with 3 neighbors, and fit the classifier to our design matrix `X`. But first we create cross validation folds. 10 sounds like a good-enough number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cv_folds = stratifiedMFolds(y_clf, 10)   # SOLUTION."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Use this to obtain a prediction on the entire data. Use `k = 3`, as example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "knn_3       = # TODO\n",
    "y_pred_cv   = cross_validate( # TODO,\n",
    "                              # TODO,\n",
    "                              # TODO,\n",
    "                              # TODO\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Calculate the area under the ROC curve for these two folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = # TODO\n",
    "cv_auc               = # TODO\n",
    "\n",
    "print 'AUC, 10-fold cross validation: %f' %(cv_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Try changing the value of `k` here. Try odd values from 1 to 29, inclusive. Compare their performances by plotting them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Question**: Why aren't we using even values here?\n",
    "\n",
    "**Answer**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-698cabd15095>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-698cabd15095>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    fpr, tpr, thresholds = # TODO\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "aurocs      = []\n",
    "classifiers = {}\n",
    "y_preds     = {}\n",
    "\n",
    "# Calculate area under the ROC curves for different values of k.\n",
    "for k in range(1, 30, 2):\n",
    "    classifiers[k] = kNNClassifier(k)        \n",
    "    y_preds[k]     = cross_validate(X_clf, y_clf, classifiers[k], cv_folds)\n",
    "    \n",
    "    fpr, tpr, thresholds = # TODO\n",
    "    aurocs.append(metrics.auc(fpr, tpr))   \n",
    "    \n",
    "# Plot these values. \n",
    "f = plt.figure()\n",
    "plt.plot(range(1, 30, 2), aurocs, color='blue')\n",
    "plt.xlabel('Number of nearest neighbors', fontsize=16)\n",
    "plt.ylabel('Cross-validated AUC', fontsize=16)\n",
    "plt.title('Nearest neighbors classification', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now compare the graph you get here, with the one you obtained using the `sklearn` implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Notice that our implementation of the *k*-nearest neighbors classifier uses the Euclidean distance measure (`pairwise_distances` uses this metric by default). However, for some types of data, some other distance measures are more useful. \n",
    "Read the documentation of `sklearn.metrics.pairwise_distances` [here](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html), and include another parameter in the definition of the class. This should subsequently be reflected in how the predict function of the class works as well. \n",
    "\n",
    "Define a new class `kNNClassifierMetric` that accepts, as argument, a distance measure to be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class kNNClassifierMetric:\n",
    "    # To start, determine what members this class must have. \n",
    "    # Recall that Python does not have public and private class members. \n",
    "    \n",
    "    # Define the __init__ function. You must also use an appropriate function prototype. \n",
    "    def __init__(self, k=3, metric='euclidean'):\n",
    "        self.k      = k\n",
    "        self.data   = None\n",
    "        self.metric = metric\n",
    "    \n",
    "    # Define the fit function. You must also use an appropriate function prototype. \n",
    "    def fit(self, X, y):\n",
    "        self.data      = X\n",
    "        # Fix class labels so that they are in [0, num_labels].\n",
    "        # TODO. You can borrow this from the previous definition.\n",
    " \n",
    "    \n",
    "    # Define the predict_proba function. You must use an appropriate function prototype. \n",
    "    def predict_proba(self, X):        \n",
    "        n_test, n_vars  = X.shape\n",
    "        n_train, n_vars = self.data.shape\n",
    "        \n",
    "        # TODO.\n",
    "        \n",
    "    # Define the predict function. You must also use an appropriate function prototype. \n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        return self.classes[np.argmax(probs, axis=1)]\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As previously, we again predict the class labels for our dataset - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "classifiers = {}\n",
    "y_preds     = {}\n",
    "# Fix a set of distance metrics to use\n",
    "d_metrics = ['euclidean', 'cityblock', 'correlation' , 'cosine']\n",
    "for m in d_metrics:\n",
    "    classifiers[m] = kNNClassifierMetric(k=3, metric=m)    \n",
    "    y_preds[m]     = # TODO\n",
    "    \n",
    "    fpr, tpr, thresholds = # TODO\n",
    "    auc                  = # TODO\n",
    "    \n",
    "    print 'Metric %s. AUC, 10-fold cross validation: %f' %(m, auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Do the same thing, but this time, try changing the parameter `k` as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "classifiers = {}    \n",
    "y_preds     = {}    \n",
    "# Fix a set of distance metrics to use\n",
    "d_metrics = ['euclidean', 'cityblock', 'correlation' , 'cosine']\n",
    "aurocs    = {}      \n",
    "\n",
    "for m in d_metrics:\n",
    "    aurocs[m] = []          \n",
    "    for k in k_range: \n",
    "        classifiers[m] = kNNClassifierMetric(k=k, metric=m)    \n",
    "        y_preds[m]     = # TODO\n",
    "        \n",
    "        fpr, tpr, thresholds = # TODO\n",
    "        auc                  = # TODO\n",
    "        aurocs[m].append(auc)     # SOLUTION.\n",
    "        \n",
    "        print 'Metric = %-12s | k = %3d | AUC = %.3f.' %(m, k, aurocs[m][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now plot all the curves on the same graph. Also try adding a legend to the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = plt.figure()\n",
    "handles = [[] for i in range(len(d_metrics))]  \n",
    "colours = ['blue', 'red', 'black', 'yellow']   \n",
    "for i in range(len(d_metrics)):                \n",
    "    handles[i], = plt.plot(k_range, aurocs[d_metrics[i]], color=colours[i])  \n",
    "\n",
    "plt.xlabel('Number of nearest neighbors', fontsize=16)\n",
    "plt.ylabel('Cross-validated AUC', fontsize=16)\n",
    "plt.title('Nearest neighbors classification', fontsize=16)\n",
    "plt.legend(handles, d_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Note the effect of choosing different distance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
